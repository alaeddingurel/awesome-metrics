**Precision** is a common metric used in the machine learning. It is mostly used in binary classification tasks and it measures the accuracy of the positive class.
This metric is also used with other metrics such as recall and f1-score in order to asses the performance of the model.


\[ \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}} \]

In this formula:

- **True Positives (TP)** are the number of instances that were correctly predicted as positive by the model.
- **False Positives (FP)** are the number of instances that were incorrectly predicted as positive when they were actually negative.
